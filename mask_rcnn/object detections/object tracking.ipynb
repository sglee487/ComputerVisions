{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2.1.0\n"
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pytesseract\n",
    "import tensorflow as tf\n",
    "import re\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.gfile = tf.io.gfile\n",
    "\n",
    "utils_ops.tf = tf.compat.v1\n",
    "\n",
    "vis_util.tf = tf.compat.v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_exist_model(model_name):\n",
    "    model_dir = model_name\n",
    "    model_dir = pathlib.Path(model_dir)/\"saved_model\"\n",
    "\n",
    "    model = tf.saved_model.load(str(model_dir))\n",
    "    model = model.signatures['serving_default']\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
    }
   ],
   "source": [
    "model_name = \"ssd_mobilenet_v1_coco_2018_01_28\"\n",
    "model = load_exist_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = 'object_detection/data/mscoco_label_map.pbtxt'\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'detection_classes': tf.float32,\n 'num_detections': tf.float32,\n 'detection_boxes': tf.float32,\n 'detection_scores': tf.float32}"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "model.output_dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'detection_classes': TensorShape([None, 100]),\n 'num_detections': TensorShape([None]),\n 'detection_boxes': TensorShape([None, 100, 4]),\n 'detection_scores': TensorShape([None, 100])}"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "model.output_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'hair drier'"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "category_index[89]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#비디오에서 적용\n",
    "\n",
    "capture = cv2.VideoCapture(\"files/training_video.mp4\") # https://github.com/IBM/powerai-counting-cars\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret, frame = capture.read()\n",
    "    \n",
    "    if (capture.get(cv2.CAP_PROP_POS_FRAMES) == capture.get(cv2.CAP_PROP_FRAME_COUNT)):\n",
    "        break\n",
    "        \n",
    "    image = np.asarray(frame)\n",
    "    input_tensor = tf.convert_to_tensor(image)\n",
    "    input_tensor = input_tensor[tf.newaxis,...]\n",
    "\n",
    "    output_dict = model(input_tensor)\n",
    "\n",
    "    # 추론 결과 표시\n",
    "    rows, cols, _ = image.shape\n",
    "    for i in range(int(output_dict['num_detections'])):\n",
    "        class_id = int(output_dict['detection_classes'][0][i])\n",
    "        score = output_dict['detection_scores'][0][i].numpy()\n",
    "        box = output_dict['detection_boxes'][0][i]\n",
    "\n",
    "        if score > 0.5:\n",
    "            x1 = int(box[1] * cols)\n",
    "            y1 = int(box[0] * rows)\n",
    "            x2 = int(box[3] * cols)\n",
    "            y2 = int(box[2] * rows)\n",
    "\n",
    "\n",
    "            cv2.putText(image, category_index[class_id]['name'] + \":\" + str(score), (x1, y1 - 5), cv2.FONT_HERSHEY_COMPLEX,\n",
    "                        1.5, (0, 0, 255), 1)\n",
    "            cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 5)\n",
    "\n",
    "    cv2.imshow(\"Object Detections\", image)\n",
    "    \n",
    "    if cv2.waitKey(33) == ord('q'): \n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비디오에서 적용\n",
    "# 객체의 움직임 표현도 같이 표시\n",
    "\n",
    "# capture = cv2.VideoCapture(\"files/bird.mp4\") # https://www.youtube.com/watch?v=XdlIbNrki5o\n",
    "capture = cv2.VideoCapture(\"files/training_video.mp4\") # https://github.com/IBM/powerai-counting-cars\n",
    "\n",
    "\n",
    "ret, prev_frame = capture.read()\n",
    "prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "prev_pts = cv2.goodFeaturesToTrack(prev_gray, mask = None, maxCorners = 1000, qualityLevel = 0.1,\n",
    "                                    minDistance = 5, blockSize = 9)\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    ret, next_frame = capture.read()\n",
    "    next_gray = cv2.cvtColor(next_frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame = next_frame.copy()\n",
    "    \n",
    "    if (capture.get(cv2.CAP_PROP_POS_FRAMES) == capture.get(cv2.CAP_PROP_FRAME_COUNT)):\n",
    "        break\n",
    "        \n",
    "    input_img = cv2.resize(frame, (300,300))\n",
    "    input_img = cv2.cvtColor(input_img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "    input_img = np.asarray(input_img)\n",
    "    input_tensor = tf.convert_to_tensor(input_img)\n",
    "    input_tensor = input_tensor[tf.newaxis,...]\n",
    "\n",
    "    output_dict = model(input_tensor)\n",
    "\n",
    "    # 추론 결과 표시\n",
    "    rows, cols, _ = image.shape\n",
    "    for i in range(int(output_dict['num_detections'])):\n",
    "        class_id = int(output_dict['detection_classes'][0][i])\n",
    "        score = output_dict['detection_scores'][0][i].numpy()\n",
    "        box = output_dict['detection_boxes'][0][i]\n",
    "\n",
    "        if score > 0.7:\n",
    "            x1 = int(box[1] * cols)\n",
    "            y1 = int(box[0] * rows)\n",
    "            x2 = int(box[3] * cols)\n",
    "            y2 = int(box[2] * rows)\n",
    "            \n",
    "            # 객체의 움직임 경로 표시\n",
    "            flow = cv2.calcOpticalFlowFarneback(prev_gray, next_gray, flow=None, pyr_scale=0.5,\n",
    "                                                levels=3, winsize=15, iterations=3, poly_n=5, poly_sigma=1.1,\n",
    "                                                flags = cv2.OPTFLOW_FARNEBACK_GAUSSIAN)\n",
    "\n",
    "            # 객체의 움직임 표현\n",
    "            magnitude, angle = cv2.cartToPolar(flow[:,:,0], flow[:,:,1], angleInDegrees=True)\n",
    "            magnitude = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)\n",
    "            angle = angle / 2\n",
    "                \n",
    "            hsv = np.zeros_like(next_frame)\n",
    "            hsv[:,:,0] = angle\n",
    "            hsv[:,:,1] = magnitude\n",
    "            hsv[:,:,2] = 255\n",
    "            frame = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "            \n",
    "            for i in range(x1, x2, 15):\n",
    "                for j in range(y1, y2, 15):\n",
    "                    x = int(flow[j, i, 0])\n",
    "                    y = int(flow[j, i, 1])\n",
    "\n",
    "                    cv2.circle(frame, (i, j), 1, (0, 0, 255), 1)\n",
    "                    cv2.line(frame, (i, j), (i + x, j + y), (0, 255, 255), 1)\n",
    "                    cv2.circle(frame, (i + x, j + y), 1, (0, 255, 255), 1)\n",
    "\n",
    "            cv2.putText(frame, category_index[class_id]['name'] + \":\" + str(score), (x1, y1 - 5), cv2.FONT_HERSHEY_COMPLEX,\n",
    "                        1.5, (0, 0, 255), 1)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 5)\n",
    "\n",
    "    cv2.imshow(\"Object Detections\", frame)\n",
    "    \n",
    "    if cv2.waitKey(33) == ord('q'): \n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('tensorflow21gpu': conda)",
   "language": "python",
   "name": "python37764bittensorflow21gpuconda335a85ba08584aab922be8dba1f7ed98"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}